# üõ°Ô∏è Detec√ß√£o de Fraude em Transa√ß√µes de Cart√£o (Cost-Sensitive)

![Python](https://img.shields.io/badge/python-3.12.7-blue.svg)

> üìπ **Nota aos Revisores (V√≠deo Explicativo)**
>
> Entendo que o volume de c√≥digos para analisar √© alto. Para otimizar seu tempo e facilitar a interpretabilidade do projeto, gravei um v√≠deo breve guiando-o pelo racioc√≠nio de neg√≥cio e pela constru√ß√£o do pipeline.
>
> **üëâ [Clique aqui para assistir ao v√≠deo](https://drive.google.com/file/d/1Gh-MfPP-QibS7Cc4YKn35aUKgQizZUR4/view?usp=sharing)**

---

Este projeto apresenta uma solu√ß√£o de Machine Learning *end-to-end* para detec√ß√£o de fraudes em cart√µes de cr√©dito. A abordagem foi desenhada para operar em um motor de decis√£o em tempo real, priorizando n√£o apenas a m√©trica de acerto estat√≠stico, mas a **minimiza√ß√£o do preju√≠zo financeiro**.

---

## 1. Contexto e Objetivo de Neg√≥cio
O desafio consiste em identificar transa√ß√µes fraudulentas em um dataset sint√©tico. A premissa central de neg√≥cio adotada √© a de que **"aprovar uma fraude (Falso Negativo) √© muito mais custoso do que negar indevidamente uma transa√ß√£o leg√≠tima"**.

* **Objetivo Principal:** Estancar perdas financeiras decorrentes de *chargebacks*.
* **Estrat√©gia:** Maximizar o **Recall** (taxa de detec√ß√£o), utilizando uma abordagem **Cost-Sensitive** (Sens√≠vel ao Custo) para priorizar a identifica√ß√£o de fraudes de alto valor monet√°rio.

---

## 2. Principais Decis√µes T√©cnicas

Seguindo a metodologia **CRISP-DM**, as seguintes decis√µes estrat√©gicas foram tomadas:

### üìä An√°lise de Dados (Data Understanding)
* **O "Sinal" nos Outliers:** A an√°lise explorat√≥ria revelou que vari√°veis como `ratio_to_median_purchase_price` possuem uma distribui√ß√£o de cauda longa. Identificamos que os valores extremos **n√£o eram ru√≠dos**, mas sim caracter√≠sticas fortes de fraude. **Decis√£o:** N√£o remover outliers para preservar o sinal do comportamento fraudulento.
* **Desbalanceamento:** O dataset possui apenas ~8.7% de fraudes, exigindo m√©tricas de avalia√ß√£o robustas (n√£o usar Acur√°cia).

### üõ†Ô∏è Engenharia e Pipeline (Data Preparation)
* **Pipeline Robusto:** Todo o pr√©-processamento foi encapsulado em um `sklearn.Pipeline` para garantir reprodutibilidade em produ√ß√£o.
* **Tratamento de Falhas:** Implementa√ß√£o de imputa√ß√£o de dados (M√©dia para cont√≠nuos, Zero para bin√°rios) para garantir que o modelo n√£o quebre caso receba dados nulos via API.
* **Escalonamento:** Uso de `MinMaxScaler` para preservar a distribui√ß√£o original dos dados sem distorcer os outliers √∫teis.

### ü§ñ Modelagem (Modeling)
Testamos tr√™s abordagens evolutivas, culminando em uma estrat√©gia de **Pesos H√≠bridos**:

1.  **Baseline Linear:** Regress√£o Log√≠stica (para estabelecer um piso de performance).
2.  **Baseline N√£o-Linear:** XGBoost "Vanilla" (para capturar complexidade).
3.  **XGBoost Weighted (Cost-Sensitive)**.
    Adotamos uma estrat√©gia de **Dupla Pondera√ß√£o** durante o treinamento:
    * **Peso de Classe (`scale_pos_weight`):** Aplicado para corrigir o desbalanceamento natural do dataset (91% Leg√≠timas vs 9% Fraudes), garantindo que o modelo d√™ a devida aten√ß√£o √† classe minorit√°ria.
    * **Peso Financeiro (`sample_weight`):** Utilizamos a vari√°vel `ratio_to_median` como peso individual de cada transa√ß√£o. Isso for√ßa o algoritmo a penalizar drasticamente erros em transa√ß√µes de alto valor (maior preju√≠zo), alinhando a fun√ß√£o de perda do modelo ao bolso da empresa.

---

## 3. Resultados Obtidos

O modelo **XGBoost Weighted** superou as outras abordagens, entregando prote√ß√£o quase total do capital em risco.

### Performance T√©cnica (Dados de Teste)
| Modelo | Recall (Detec√ß√£o) | Precision | F1-Score | ROC-AUC |
| :--- | :---: | :---: | :---: | :---: |
| Logistic Regression | 41.18% | 91.90% | 0.57 | 0.95 |
| XGBoost Simples | 99.11% | 98.89% | 0.99 | 0.99 |
| **XGBoost Weighted** | **99.90%** | 98.97% | 0.99 | 0.99 |

> **Destaque:** A valida√ß√£o cruzada (folds estratificados) confirmou a estabilidade do modelo com um desvio padr√£o √≠nfimo (**0.0004**), eliminando riscos de *Overfitting*.

#### Visualiza√ß√£o Comparativa (Matriz de Confus√£o)
Abaixo, comparamos onde cada modelo errou. Note como o modelo final (√† direita) praticamente zera os Falsos Negativos.

![Matriz de Confus√£o Comparativa](./assets/confusion_matrix.png)

### Impacto Financeiro (Simula√ß√£o)
Utilizando a raz√£o do valor da compra como proxy financeiro:

| Modelo | Valor "Perdido" (Fraudes que passaram) | Redu√ß√£o de Perda |
| :--- | :---: | :---: |
| XGBoost Simples | 571 unidades | - |
| **XGBoost Weighted** | **88 unidades** | **~85% menor que o modelo simples** |

O modelo final deixou passar apenas 88 unidades de valor, contra 571 do modelo padr√£o, provando a efic√°cia da estrat√©gia de pesos h√≠bridos.

---

## 4. Plano de Deploy e Monitoramento

A produtiza√ß√£o do modelo (MLOps) segue uma arquitetura de microsservi√ßos para alta disponibilidade.

1.  **Empacotamento:** O pipeline treinado (Pr√©-processamento + Modelo) √© serializado em um arquivo `.pkl`.
2.  **API de Infer√™ncia:** Desenvolvimento de uma API **FastAPI** com endpoint `POST /predict` para receber os dados da transa√ß√£o e retornar a probabilidade de fraude em milissegundos.
3.  **Containeriza√ß√£o:** A aplica√ß√£o √© isolada em um container **Docker** para garantir paridade entre os ambientes de desenvolvimento e produ√ß√£o.

### Estrat√©gia de Monitoramento
* **Data Drift:** Monitoramento cont√≠nuo da m√©dia de vari√°veis cr√≠ticas (ex: `distance_from_home`). Desvios bruscos disparam alertas de re-treino.
* **Business KPI:** Monitoramento da **Taxa de Bloqueio**. Se o modelo come√ßar a bloquear >20% das transa√ß√µes (m√©dia hist√≥rica ~8%), um *Kill Switch* √© acionado para revis√£o manual.
* **Ciclo de Vida:** Re-treino mensal programado com os novos dados de chargebacks confirmados (Feedback Loop).

---

## 5. Como Reproduzir

1.  Clone este reposit√≥rio.
2.  Instale as depend√™ncias:
    ```bash
    pip install -r requirements.txt
    ```
3.  Execute o notebook `Fraud_Detection.ipynb` para visualizar toda a an√°lise, treinamento e valida√ß√£o.

---
**Autor:** Gustavo Villanova Vecchio
